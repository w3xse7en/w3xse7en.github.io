[{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"zh","lastmod":1600599009,"objectID":"5a65ad8e6ca7097753803f6dd2d1682c","permalink":"https://w3xse7en.github.io/docs/lang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/docs/lang/","section":"docs","summary":"Go","tags":null,"title":"Golang","type":"book"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"zh","lastmod":1604248323,"objectID":"994056305b5f894589543b14916cef5b","permalink":"https://w3xse7en.github.io/docs/os/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/docs/os/","section":"docs","summary":"Operate System","tags":null,"title":"OS","type":"book"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"zh","lastmod":1604816759,"objectID":"556b8bb8996a733449f60c0605d40e27","permalink":"https://w3xse7en.github.io/docs/sql/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/docs/sql/","section":"docs","summary":"Structured Query Language","tags":null,"title":"SQL","type":"book"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"zh","lastmod":1600599009,"objectID":"c9795c39ea4320aa318cd11f1a77ba16","permalink":"https://w3xse7en.github.io/docs/web/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/docs/web/","section":"docs","summary":"net","tags":null,"title":"Web","type":"book"},{"authors":null,"categories":null,"content":"Building ","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"zh","lastmod":1600599009,"objectID":"4cdd37113783e47641dd300543c94e1b","permalink":"https://w3xse7en.github.io/docs/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/docs/","section":"docs","summary":"Building ","tags":null,"title":"Introduction","type":"book"},{"authors":null,"categories":null,"content":" 考虑要为公司安装k8s，先尝试在本地搭建模拟k8s\n记录安装k8s过程的点点滴滴\n再次熟悉熟悉整个k8s架构\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"zh","lastmod":1602001847,"objectID":"b7c08c4e7ef8a3056c62ac89dde460cf","permalink":"https://w3xse7en.github.io/k8s_local/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/k8s_local/","section":"k8s_local","summary":"考虑要为公司安装k8s，先尝试在本地搭建模拟k8s\n记录安装k8s过程的点点滴滴\n再次熟悉熟悉整个k8s架构","tags":null,"title":"介绍","type":"book"},{"authors":null,"categories":null,"content":"defer defer 是否会在panic后执行\ninterface  writing generic algorithm hiding implementation detail providing interception points  interface拥有两个指针 一个指向类型 一个指向具体值\nslice 分配在连续的内存地址上\n元素类型一致，元素存储宽度一致\n空间大小固定，不能修改\n可以通过索引计算出元素对应存储的位置（只需要知道数组内存的起始位置和数据元素宽度即可）\n会出现数据溢出的问题（下标越界）\nslice扩容 如果新的slice大小是当前大小2倍以上，则大小增长为新大小\n如果当前slice cap 小于1024，按每次2倍增长，否则每次按当前大小1/4增长。直到增长的大小超过或等于新大小\nappend的实现是在内存中将slice的array值赋值到新申请的array上\n性能\n通过上面我们知道slice的扩容涉及到内存的拷贝，这样带来的好处是数据存储在连续内存上，比随机访问快很多，最直接的性能提升就是缓存命中率会高很多,这也就是为什么slice不采用动态链表实现的原因吧\n我们知道拷贝内存数据是有开销的， 而其中最大的开销不在 memmove\n数据上，而是在开辟一块新内存malloc及之后的GC压力\n拷贝连续内存是很快的，随着cap变大，拷贝总成本还是 O(N) ,只是常数大了\n假如不想发生拷贝，那你就没有连续内存。此时随机访问开销会是：链表 O(N)\n当你能大致知道所需的最大空间（在大部分时候都是的）时，在make的时候预留相应的 cap 就好 如果需要的空间很大，而且每次都不确定，那就要在浪费内存和耗 CPU 在 malloc + gc 上做权衡 链表的查找操作是从第一个元素开始，所以相对数组要耗时间的多，因为采用这样的结构对读的性能有很大的提高\nmysql 性能调优 SQL优化 小表驱动大表 limit限定 索引添加 适当添加冗余字段，减少表关联。\n系统优化 max_connections 最大连接数\ninnodb_buffer_pool_size 数据缓冲区buffer pool大小\nsort_buffer_size 排序缓冲区内存大小\njoin_buffer_size 使用连接缓冲区大小\nread_buffer_size 全表扫描时分配的缓冲区大小\n缓存 主动式缓存 用户更新数据 同时更新缓存\n被动式缓存 用户更新数据 删除缓存，被读取时载入缓存\nMaps 线程不安全\n底层使用的hash结构\nhash算法使用aes hash hash值分为 高位hash和低位hash\n高位哈希值：是用来确定当前的bucket（桶）有没有所存储的数据的 bmap a bucket for a Go map\n低位哈希值：是用来确定，当前的数据存在了哪个bucket（桶）hmap a header for a go map\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1602118627,"objectID":"463e85d8ce80424f68c73ca2404fe50c","permalink":"https://w3xse7en.github.io/docs/lang/go/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/docs/lang/go/","section":"docs","summary":"defer defer 是否会在panic后执行\ninterface  writing generic algorithm hiding implementation detail providing interception points  interface拥有两个指针 一个指向类型 一个指向具体值\nslice 分配在连续的内存地址上\n元素类型一致，元素存储宽度一致\n空间大小固定，不能修改\n可以通过索引计算出元素对应存储的位置（只需要知道数组内存的起始位置和数据元素宽度即可）\n会出现数据溢出的问题（下标越界）\nslice扩容 如果新的slice大小是当前大小2倍以上，则大小增长为新大小\n如果当前slice cap 小于1024，按每次2倍增长，否则每次按当前大小1/4增长。直到增长的大小超过或等于新大小\nappend的实现是在内存中将slice的array值赋值到新申请的array上","tags":null,"title":"Go","type":"book"},{"authors":null,"categories":null,"content":"goroutine leak 协程泄露 Goroutine为什么没有ID号\nGoroutine调度 G P M 抢占式调度\n动态栈\n协程，线程，进程的区别 进程 进程是具有一定独立功能的程序关于某个数据集合上的一次运行活动,进程是系统进行资源分配和调度的一个独立单位。每个进程都有自己的独立内存空间，不同进程通过进程间通信来通信。由于进程比较重量，占据独立的内存，所以上下文进程间的切换开销（栈、寄存器、虚拟内存、文件句柄等）比较大，但相对比较稳定安全。\n线程 线程是进程的一个实体,是CPU调度和分派的基本单位,它是比进程更小的能独立运行的基本单位.线程自己基本上不拥有系统资源,只拥有一点在运行中必不可少的资源(如程序计数器,一组寄存器和栈),但是它可与同属一个进程的其他的线程共享进程所拥有的全部资源。线程间通信主要通过共享内存，上下文切换很快，资源开销较少，但相比进程不够稳定容易丢失数据。\n协程 协程是一种用户态的轻量级线程，协程的调度完全由用户控制。协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈，直接操作栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切换非常快。\nchannel select sync ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1600599009,"objectID":"9f49950b7dc601a23d820aa87a66214c","permalink":"https://w3xse7en.github.io/docs/lang/goroutine/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/docs/lang/goroutine/","section":"docs","summary":"goroutine leak 协程泄露 Goroutine为什么没有ID号\nGoroutine调度 G P M 抢占式调度\n动态栈\n协程，线程，进程的区别 进程 进程是具有一定独立功能的程序关于某个数据集合上的一次运行活动,进程是系统进行资源分配和调度的一个独立单位。每个进程都有自己的独立内存空间，不同进程通过进程间通信来通信。由于进程比较重量，占据独立的内存，所以上下文进程间的切换开销（栈、寄存器、虚拟内存、文件句柄等）比较大，但相对比较稳定安全。\n线程 线程是进程的一个实体,是CPU调度和分派的基本单位,它是比进程更小的能独立运行的基本单位.线程自己基本上不拥有系统资源,只拥有一点在运行中必不可少的资源(如程序计数器,一组寄存器和栈),但是它可与同属一个进程的其他的线程共享进程所拥有的全部资源。线程间通信主要通过共享内存，上下文切换很快，资源开销较少，但相比进程不够稳定容易丢失数据。\n协程 协程是一种用户态的轻量级线程，协程的调度完全由用户控制。协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈，直接操作栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切换非常快。\nchannel select sync ","tags":null,"title":"Goroutine","type":"book"},{"authors":null,"categories":null,"content":" 目录  进程  什么是孤儿进程 什么是僵尸进程 进程上下文 内核与用户 进程状态转换 进程间通信的同步/异步， 阻塞/非阻塞   线程  线程上下文 线程上下文切换耗时比进程大吗？   协程 参考    进程  进程是资源封装的单位。 进程封装的资源包括：内存、文件、文件系统、信号、控制台等等。\n 在任意时刻， 一个 CPU 核心上（processor）只可能运行一个进程 。  什么是孤儿进程  当父进程退出时，它的子进程们（一个或者多个）就成了孤儿进程  当孤儿进程结束后，init进程会释放孤儿进程的资源，因此孤儿进程不会有危害\n一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。 由于孤儿进程会被init进程给收养，所以孤儿进程不会对系统造成危害。\n什么是僵尸进程  子进程先退出，而父进程又没有去处理回收释放子进程的资源，这个时候子进程就成了僵尸进程  通常系统的进程数量都是有限制的，如果有大量的僵尸进程占用进程号，导致新的进程无法创建\n在fork()/execve()过程中，假设子进程结束时父进程仍存在，而父进程fork()之前既没安装SIGCHLD信号处理函数调用waitpid()等待子进程结束，又没有显式忽略该信号，则子进程成为僵死进程，无法正常结束，此时即使是root身份kill -9也不能杀死僵死进程。\n进程上下文  当一个进程在执行时,CPU的所有寄存器中的值、进程的状态以及堆栈中的内容被称为该进程的上下文。  当内核需要切换到另一个进程时，它需要保存当前进程的所有状态，即保存当前进程的上下文，以便在再次执行该进程时，能够必得到切换时的状态执行下去。\n在LINUX中，当前进程上下文均保存在进程的任务数据结构中。\n在发生中断时,内核就在被中断进程的上下文中，在内核态下执行中断服务例程。但同时会保留所有需要用到的资源，以便中继服务结束时能恢复被中断进程的执行。\n 发生进程上下文切换的场景   为了保证所有进程可以得到公平调度，CPU 时间被划分为一段段的时间片，这些时间片再被轮流分配给各个进程。这样，当某个进程的时间片耗尽了，就会被系统挂起，切换到其它正在等待 CPU 的进程运行。 进程在系统资源不足（比如内存不足）时，要等到资源满足后才可以运行，这个时候进程也会被挂起，并由系统调度其他进程运行。 当进程通过睡眠函数 sleep 这样的方法将自己主动挂起时，自然也会重新调度。 当有优先级更高的进程运行时，为了保证高优先级进程的运行，当前进程会被挂起，由高优先级进程来运行 发生硬件中断时，CPU 上的进程会被中断挂起，转而执行内核中的中断服务程序。  内核与用户  当进程在执行用户自己的代码时，则称其处于用户运行态（用户态）。  此时处理器在特权级最低的（3级）用户代码中运行。当正在执行用户程序而突然被中断程序中断时，此时用户程序也可以象征性地称为处于进程的内核态。因为中断处理程序将使用当前进程的内核栈。\n 当一个任务（进程）执行系统调用而陷入内核代码中执行时，称进程处于内核运行态（内核态）。  此时处理器处于特权级最高的（0级）内核代码中执行。当进程处于内核态时，执行的内核代码会使用当前进程的内核栈。每个进程都有自己的内核栈。\n进程状态转换   进程状态轮转图   上图展示了一个进程的不同状态\n New. 进程正在被创建. Ready. 进程在等待被操作系统调度 Running. 进程的指令正在被执行 Waiting. 进程正在等待一些事件的发生（例如 I/O 的完成或者收到某个信号） Terminated. 进程执行完毕（可能是被强行终止的）     在程序中，创建一个MySQL Client实例，对应创建进程 MySQL Client启动时会连接MySQL Server，等待MySQL语句执行，对应进程就绪 使用MySQL Client执行Select语句，对应进程运行 等待MySQL Server返回Select结果，对应进程阻塞 Select结果返回后，MySQL Client重新等待语句执行，对应进程就绪 MySQL Client 执行exit操作，对应进程运行，中止MySQL Client 对应进程中止  进程间通信的同步/异步， 阻塞/非阻塞   进程间的通信是通过 send() 和 receive() 两种基本操作完成的。具体如何实现这两种基础操作，存在着不同的设计。 消息的传递有可能是阻塞的或非阻塞的 – 也被称为同步或异步的\n  阻塞式发送（blocking send）发送方进程会被一直阻塞， 直到消息被接受方进程收到。\n  非阻塞式发送（nonblocking send）。发送方进程调用 send() 后， 立即就可以其他操作。\n  阻塞式接收（blocking receive） 接收方调用 receive() 后一直阻塞， 直到消息到达可用。\n  非阻塞式接受（nonblocking receive） 接收方调用 receive() 函数后， 要么得到一个有效的结果， 要么得到一个空值， 即不会被阻塞。\n   线程 线程则是Linux的调度单位，共享同一个进程下的资源。 Linux内核调度器是以线程为单位进行调度和上下文切换的。\n线程上下文  线程是调度的基本单位，而进程则是资源拥有的基本单位。  说白了，所谓内核中的任务调度，实际上的调度对象是线程；而进程只是给线程提供了虚拟内存、全局变量等资源。\n所以，对于线程和进程，我们可以这么理解：\n 当进程只有一个线程时，可以认为进程就等于线程。 当进程拥有多个线程时，这些线程会共享相同的虚拟内存和全局变量等资源。这些资源在上下文切换时是不需要修改的。另外，线程也有自己的私有数据，比如栈和寄存器等，这些在上下文切换时也是需要保存的。   发生线程上下文切换的场景   前后两个线程属于不同进程。此时，因为资源不共享，所以切换过程就跟进程上下文切换是一样。 前后两个线程属于同一个进程。此时，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据  线程上下文切换耗时比进程大吗？  从上下文切换的耗时上来看，Linux线程（轻量级进程）其实和进程差别不太大。   协程  参考 孤儿进程、僵尸进程和守护进程\n面试官问：僵尸进程和孤儿进程有了解过吗\n用户空间与内核空间，进程上下文与中断上下文[总结]\n进程/线程上下文切换会用掉你多少CPU\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1604816759,"objectID":"e442ea7315686f6522f58035bdd3ec30","permalink":"https://w3xse7en.github.io/docs/os/process/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/docs/os/process/","section":"docs","summary":"目录  进程  什么是孤儿进程 什么是僵尸进程 进程上下文 内核与用户 进程状态转换 进程间通信的同步/异步， 阻塞/非阻塞   线程  线程上下文 线程上下文切换耗时比进程大吗？   协程 参考    进程  进程是资源封装的单位。 进程封装的资源包括：内存、文件、文件系统、信号、控制台等等。\n 在任意时刻， 一个 CPU 核心上（processor）只可能运行一个进程 。  什么是孤儿进程  当父进程退出时，它的子进程们（一个或者多个）就成了孤儿进程  当孤儿进程结束后，init进程会释放孤儿进程的资源，因此孤儿进程不会有危害","tags":null,"title":"process","type":"book"},{"authors":null,"categories":null,"content":" 目录   ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1604816759,"objectID":"40c6ea0147ab08e947a09e48f708b47d","permalink":"https://w3xse7en.github.io/docs/sql/redis/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/docs/sql/redis/","section":"docs","summary":" 目录   ","tags":null,"title":"redis","type":"book"},{"authors":null,"categories":null,"content":" 目录  I/O模型  Blocking I/O - 阻塞I/O Nonblocking I/O - 非阻塞I/O I/O Multiplexing - I/O多路复用 Signal-Driven I/O - 信号驱动I/O Asynchronous I/O - 异步I/O 五种 I/O 模型比较   select  select遇到的问题   epoll  epoll是如何解决select的三个问题 epoll的伪码描述   参考    I/O模型 [UNIX: registered: Network Programming] 提供了5种IO模型\nBlocking I/O - 阻塞I/O   Nonblocking I/O - 非阻塞I/O   I/O Multiplexing - I/O多路复用   Signal-Driven I/O - 信号驱动I/O   Asynchronous I/O - 异步I/O   五种 I/O 模型比较    select io多路复用是为了解决一个进程同时处理多个socket问题\n一个简单的思路是\n假设有N个socket链接，检测有socket接收到数据，遍历所有socket进行处理\n// fds = file decriptors for { select (fds) // wait while fds poll callback POLL_IN for fd range fds{ if fd has data{ read fd } } }   被监控的fds需要从用户空间拷贝到内核空间 为了减少数据拷贝带来的性能损坏，内核对被监控的fds集合大小做了限制，并且这个是通过宏控制的，大小不可改变(限制为1024)。 被监控的fds集合中，只要有一个有数据可读，整个socket集合就会被遍历一次调用sk的poll函数收集可读事件 由于当初的需求是朴素，仅仅关心是否有数据可读这样一个事件，当事件通知来的时候，由于数据的到来是异步的，我们不知道事件来的时候，有多少个被监控的socket有数据可读了，于是，只能挨个遍历每个socket来收集可读事件。  select遇到的问题 总共有三个问题需要解决\n 被监控的fds集合大小被限制了1024，不够用 fds集合需要从用户空间拷贝到内核空间的问题，耗费性能 需要遍历fds集合才能知道有数据接收的fds列表  epoll epoll 是对 select 和 poll 的改进，避免了“性能开销大”和“文件描述符数量少”两个缺点。\nepoll 有以下几个特点：\n 使用红黑树存储文件描述符集合 使用队列存储就绪的文件描述符 每个文件描述符只需在添加时传入一次；通过事件更改文件描述符状态  epoll一共有3个接口\n epoll_create创建epoll实例，其实例内部存储：  监听列表：所有要监听的文件描述符，使用红黑树\n就绪列表：所有就绪的文件描述符，使用队列\nepoll_ctl用来维护监视列表，可以添加或删除所要监听的 socket  epoll_ctl 会将文件描述符 fd 添加到 epoll 实例的监听列表里，同时为 fd 设置一个回调函数，并监听事件event。当fd上发生相应事件时，会调用回调函数，将 fd 添加到 epoll 实例的就绪队列上。\n当调用epoll_wait时，如果就绪列表中存在socket，则直接返回，如果没有，则阻塞进程  epoll是如何解决select的三个问题  被监控的fds集合大小被限制了1024，不够用 select 使用整型数组存储文件描述符集合，而 epoll 使用红黑树存储，数量较大。\n  fds集合需要从用户空间拷贝到内核空间的问题，耗费性能 epoll通过内核与用户空间使用mmap(内存映射)，将用户空间的一块地址和内核空间的一块地址同时映射到相同的一块物理内存地址，减少用户态和内核态之间的数据交换。\nepoll 对于每个描述符，只需要在 epoll_ctl 传递一次，之后 epoll_wait 不需要再次传递这也大大提高了效率。\n  需要遍历fds集合才能知道有数据接收的fds列表 epoll_ctl 中为每个文件描述符指定了回调函数，并在就绪时将其加入到就绪列表，因此 epoll 不需要像 select 那样遍历检测每个文件描述符，只需要判断就绪列表是否为空即可。这样，在没有描述符就绪时，epoll 能更早地让出系统资源。\n相当于时间复杂度从 O(n) 降为 O(1)\n epoll的伪码描述 for{ active_fd = epoll_wait(fds) read fd }   参考 Chapter 6. I/O Multiplexing: The select and poll Functions\nSocket\n【操作系统】I/O 多路复用，select / poll / epoll 详解\n怎样理解阻塞非阻塞与同步异步的区别\n大话 Select、Poll、Epoll\n源码解读epoll内核机制\n  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1604816759,"objectID":"27960c5fe7ed9ff51b1732d265dbdc7a","permalink":"https://w3xse7en.github.io/docs/web/socket/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/docs/web/socket/","section":"docs","summary":"目录  I/O模型  Blocking I/O - 阻塞I/O Nonblocking I/O - 非阻塞I/O I/O Multiplexing - I/O多路复用 Signal-Driven I/O - 信号驱动I/O Asynchronous I/O - 异步I/O 五种 I/O 模型比较   select  select遇到的问题   epoll  epoll是如何解决select的三个问题 epoll的伪码描述   参考    I/O模型 [UNIX: registered: Network Programming] 提供了5种IO模型","tags":null,"title":"socket","type":"book"},{"authors":null,"categories":null,"content":"Q\u0026amp;A ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1600599009,"objectID":"733b544858ce4675758be5bc20ab3acc","permalink":"https://w3xse7en.github.io/docs/lang/qa/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/docs/lang/qa/","section":"docs","summary":"Q\u0026amp;A ","tags":null,"title":"Q\u0026A","type":"book"},{"authors":null,"categories":null,"content":" Centos  清华大学centos7.8.2003镜像    清华大学镜像站   虚拟机  宿主机i5-6200u 2c16g 每台机器均为2c4g配置    hyper-v   网络  安装完的centos是不能上网的 此处使用桥接模式进行网络连接 使用桥接模式 使node和host处在同一网段更方便其他设备访问      桥接详情    配置Centos 静态ip地址 网段参考网桥ip  vi /etc/sysconfig/network-scripts/ifcfg-eth0 ONBOOT=yes BOOTPROTO=static IPADDR=192.168.1.201 NETMASK=255.255.255.0 GATEWAY=192.168.1.1 DNS1=192.168.1.1 service network restart    网络拓扑图   ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1606449303,"objectID":"15ca4fc21c04612c6bfb72a9d502d26c","permalink":"https://w3xse7en.github.io/k8s_local/10_hyper-v_install_centos/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/k8s_local/10_hyper-v_install_centos/","section":"k8s_local","summary":"Centos  清华大学centos7.8.2003镜像    清华大学镜像站   虚拟机  宿主机i5-6200u 2c16g 每台机器均为2c4g配置    hyper-v   网络  安装完的centos是不能上网的 此处使用桥接模式进行网络连接 使用桥接模式 使node和host处在同一网段更方便其他设备访问      桥接详情    配置Centos 静态ip地址 网段参考网桥ip  vi /etc/sysconfig/network-scripts/ifcfg-eth0 ONBOOT=yes BOOTPROTO=static IPADDR=192.","tags":null,"title":"hyper-v 安装 centos","type":"book"},{"authors":null,"categories":null,"content":" 参考 kubespray\n[ Kube 65.1 ] Kubespray - Kubernetes cluster provisioning\nDeploying kubernetes using Kubespray\nINSTALLING A MULTINODE KUBERNETES CLUSTER USING KUBESPRAY\nit\u0026rsquo;s really really really hard run kubespray in china! #6207\n使用kubespray安装kubernetes\n使用kubespray搭建生产级高可用集群\n使用Kubespray安装k8s集群\ndocker/kubernetes国内源/镜像源解决方式\n  配置免密码登录 ssh-keygen -t rsa ssh-copy-id root@192.168.1.200 ssh-copy-id root@192.168.1.201 ssh-copy-id root@192.168.1.202   下载kubespray # master分支还在更新中，此处使用当前最新release的版本v2.14.1 git clone --single-branch -b v2.14.1 https://github.com/kubernetes-sigs/kubespray.git   安装python3-pip yum install python3-pip   安装kubespray依赖 pip3 install -r requirements.txt -i https://mirrors.aliyun.com/pypi/simple/   使用ansible对每台机器进行批处理 配置ansible访问k8s集群hosts\nvi /etc/ansible/hosts  [k8s] 192.168.1.200 ansible_ssh_user=root 192.168.1.201 ansible_ssh_user=root 192.168.1.202 ansible_ssh_user=root   测试  ansible k8s -m ping   更新yum  ansible k8s -m shell -a 'yum update -y'   安装ntp服务，统一集群时间  ansible k8s -m shell -a 'yum install -y ntp \u0026amp;\u0026amp; systemctl enable ntpd \u0026amp;\u0026amp; systemctl start ntpd \u0026amp;\u0026amp; timedatectl set-timezone Asia/Shanghai \u0026amp;\u0026amp; timedatectl set-ntp yes \u0026amp;\u0026amp; ntpq -p'   配置ipv4转发  ansible k8s -m shell -a 'echo net.ipv4.ip_forward = 1 \u0026gt;\u0026gt; /etc/sysctl.conf \u0026amp;\u0026amp; sysctl -p'   关闭防火墙  ansible k8s -m shell -a 'systemctl stop firewalld \u0026amp;\u0026amp; systemctl disable firewalld'   生成kubespray所需配置  创建可自定义的配置  cp -rfp inventory/sample inventory/mycluster   IPS=(此处填写k8s集群的ip地址，注意空格分割)  declare -a IPS=(192.168.1.200 192.168.1.201 192.168.1.202)  CONFIG_FILE=inventory/mycluster/hosts.yaml python3 contrib/inventory_builder/inventory.py ${IPS[@]}   查看生成的hosts.yaml  cat inventory/mycluster/hosts.yaml   此处是 2个master 3个node 3个etcd 的高可用配置，可以根据喜好进行配置  all: hosts: node1: ansible_host: 192.168.1.200 ip: 192.168.1.200 access_ip: 192.168.1.200 node2: ansible_host: 192.168.1.201 ip: 192.168.1.201 access_ip: 192.168.1.201 node3: ansible_host: 192.168.1.202 ip: 192.168.1.202 access_ip: 192.168.1.202 children: kube-master: hosts: node1: node2: kube-node: hosts: node1: node2: node3: etcd: hosts: node1: node2: node3: k8s-cluster: children: kube-master: kube-node: calico-rr: hosts: {}   下载依赖   方案1\n 将所有源换成国内镜像加速    方案2\n 离线安装    方案3\n 设置代理    此处使用方案3\n  vi inventory/mycluster/group_vars/all/all.yml http_proxy: \u0026quot;http://192.168.1.9:1080\u0026quot; https_proxy: \u0026quot;http://192.168.1.9:1080\u0026quot;    在阿里云环境下使用代理\n 开启自己电脑上的http proxy server 使用frp将本地电脑http proxy port 映射至公网 配置http_proxy 直接在阿里云内使用代理可能会被警告，因此使用frp做一层中转    配置docker镜像源\n  vi inventory/mycluster/group_vars/all/docker.yml ## Add other registry,example China registry mirror. docker_registry_mirrors: - https://mirror.aliyuncs.com - https://registry.docker-cn.com   提前下载k8s所需依赖，避免安装时报错  ansible-playbook -i inventory/mycluster/hosts.yaml --become --become-user=root cluster.yml --tags container_engine ansible-playbook -i inventory/mycluster/hosts.yaml --become --become-user=root cluster.yml --tags download   若遇到报错，可尝试将http_proxy注释掉重新下载，重复试几次后一般都能下完  阿里云apt, yum等源设置的是内网地址，需要直连才可以访问    vi inventory/mycluster/group_vars/all/all.yml # http_proxy: \u0026quot;http://192.168.1.9:1080\u0026quot; # https_proxy: \u0026quot;http://192.168.1.9:1080\u0026quot;    frp-v2ray-代理下载    ubuntu 系统安装完毕后，请删除/etc/apt/apt.conf里的代理配置    (可选)开启helm vi inventory/mycluster/group_vars/k8s-cluster/addons.yml # Helm deployment helm_enabled: true   安装 ansible-playbook -i inventory/mycluster/hosts.yaml --become --become-user=root cluster.yml    安装花费21分钟    验证   k8s v1.18.9安装成功    重置  若在安装过程中遇到问题可用以下命令重置  ansible-playbook -i inventory/mycluster/hosts.yaml reset.yml   Dashboard  Kubespray并没有替你创建用户，所以需要创建用户，然后获得Token，使用Token登录。    添加admin-user用户  cat \u0026lt;\u0026lt;EOF | kubectl apply -f - apiVersion: v1 kind: ServiceAccount metadata: name: admin-user namespace: kube-system --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: admin-user roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-admin subjects: - kind: ServiceAccount name: admin-user namespace: kube-system EOF   获取admin-user的token  kubectl -n kube-system describe secret $(kubectl -n kube-system get secret | grep admin-user | awk '{print $1}')   访问dashboard  https://192.168.1.200:6443/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/#!/login    services \u0026quot;https:kubernetes-dashboard:\u0026quot; is forbidden: User \u0026quot;system:anonymous\u0026quot; cannot get services/proxy in the namespace \u0026quot;kube-system\u0026quot;\n遇到此问题请查看system:anonymous 无法访问 k8s dashboard\n  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1606449303,"objectID":"d22069fec87a90526a36afdd637829ea","permalink":"https://w3xse7en.github.io/k8s_local/20_install_k8s/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/k8s_local/20_install_k8s/","section":"k8s_local","summary":"参考 kubespray\n[ Kube 65.1 ] Kubespray - Kubernetes cluster provisioning\nDeploying kubernetes using Kubespray\nINSTALLING A MULTINODE KUBERNETES CLUSTER USING KUBESPRAY\nit\u0026rsquo;s really really really hard run kubespray in china!","tags":null,"title":"kubespray 安装 k8s","type":"book"},{"authors":null,"categories":null,"content":" 参考 kubespray\n[ Kube 65.3 ] Kubespray - Adding \u0026amp; Removing Kubernetes nodes\n  添加节点 配置ansible访问新节点(192.168.1.203) vi /etc/ansible/hosts  [k8s] 192.168.1.200 ansible_ssh_user=root 192.168.1.201 ansible_ssh_user=root 192.168.1.202 ansible_ssh_user=root 192.168.1.203 ansible_ssh_user=root   测试  ansible k8s -m ping   更新新节点功能(时区,防火墙等)  新增node4 vi inventory/mycluster/hosts.yaml  all: hosts: node1: ansible_host: 192.168.1.200 ip: 192.168.1.200 access_ip: 192.168.1.200 node2: ansible_host: 192.168.1.201 ip: 192.168.1.201 access_ip: 192.168.1.201 node3: ansible_host: 192.168.1.202 ip: 192.168.1.202 access_ip: 192.168.1.202 node4: ansible_host: 192.168.1.203 ip: 192.168.1.203 access_ip: 192.168.1.203 children: kube-master: hosts: node1: node2: kube-node: hosts: node1: node2: node3: node4: etcd: hosts: node1: node2: node3: k8s-cluster: children: kube-master: kube-node: calico-rr: hosts: {}  下载依赖  假设node1与node4为同系统 将node1 /tmp/releases copy至node4 /tmp/releases即可避免node4再次下载k8s依赖组件  scp /tmp/releases root@192.168.1.203:/tmp/releases   确定依赖已完善  ansible-playbook -i inventory/mycluster/hosts.yaml --become --become-user=root cluster.yml --tags container_engine ansible-playbook -i inventory/mycluster/hosts.yaml --become --become-user=root cluster.yml --tags download  添加节点 ansible-playbook -i inventory/mycluster/hosts.yaml scale.yml    移除节点 ansible-playbook -i inventory/mycluster/hosts.yaml remove-node.yml --extra-vars \u0026quot;node=node4\u0026quot;  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1606449303,"objectID":"840988aab8191fa2b3fd2afa619af0ed","permalink":"https://w3xse7en.github.io/k8s_local/30_add_remove_node/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/k8s_local/30_add_remove_node/","section":"k8s_local","summary":"参考 kubespray\n[ Kube 65.3 ] Kubespray - Adding \u0026amp; Removing Kubernetes nodes\n  添加节点 配置ansible访问新节点(192.168.1.203) vi /etc/ansible/hosts  [k8s] 192.168.1.200 ansible_ssh_user=root 192.168.1.201 ansible_ssh_user=root 192.168.1.202 ansible_ssh_user=root 192.168.1.203 ansible_ssh_user=root   测试  ansible k8s -m ping   更新新节点功能(时区,防火墙等)  新增node4 vi inventory/mycluster/hosts.","tags":null,"title":"添加/删除节点","type":"book"},{"authors":null,"categories":null,"content":" 参考 Setting up a Kubernetes CI/CD Service Account\n   场景  权限划分，cicd限定namespace=dev使用kubectl apply -f部署服务\n 创建 namespace dev  cat \u0026lt;\u0026lt;EOF | kubectl apply -f - { \u0026quot;apiVersion\u0026quot;: \u0026quot;v1\u0026quot;, \u0026quot;kind\u0026quot;: \u0026quot;Namespace\u0026quot;, \u0026quot;metadata\u0026quot;: { \u0026quot;name\u0026quot;: \u0026quot;dev\u0026quot;, \u0026quot;labels\u0026quot;: { \u0026quot;name\u0026quot;: \u0026quot;dev\u0026quot; } } } EOF  创建 service account cicd-user # 该脚本依赖 jq 组件 yum install jq -y # [可修改] SERVICE_ACCOUNT_NAME=\u0026quot;cicd-user\u0026quot; # [可修改] NAMESPACE=\u0026quot;dev\u0026quot; # [可修改] TARGET_FOLDER=\u0026quot;/home/k8s/kube\u0026quot; kubectl create sa \u0026quot;${SERVICE_ACCOUNT_NAME}\u0026quot; --namespace \u0026quot;${NAMESPACE}\u0026quot; mkdir -p \u0026quot;${TARGET_FOLDER}\u0026quot; SECRET_NAME=$(kubectl get sa \u0026quot;${SERVICE_ACCOUNT_NAME}\u0026quot; --namespace=\u0026quot;${NAMESPACE}\u0026quot; -o json | jq -r .secrets[].name) kubectl get secret --namespace \u0026quot;${NAMESPACE}\u0026quot; \u0026quot;${SECRET_NAME}\u0026quot; -o json | jq -r '.data[\u0026quot;ca.crt\u0026quot;]' | base64 --decode \u0026gt; \u0026quot;${TARGET_FOLDER}/ca.crt\u0026quot; USER_TOKEN=$(kubectl get secret --namespace \u0026quot;${NAMESPACE}\u0026quot; \u0026quot;${SECRET_NAME}\u0026quot; -o json | jq -r '.data[\u0026quot;token\u0026quot;]' | base64 --decode) KUBECFG_FILE_NAME=\u0026quot;${TARGET_FOLDER}/k8s-${SERVICE_ACCOUNT_NAME}-${NAMESPACE}-conf\u0026quot; context=$(kubectl config current-context) CLUSTER_NAME=$(kubectl config get-contexts \u0026quot;$context\u0026quot; | awk '{print $3}' | tail -n 1) ENDPOINT=$(kubectl config view \\ -o jsonpath=\u0026quot;{.clusters[?(@.name == \\\u0026quot;${CLUSTER_NAME}\\\u0026quot;)].cluster.server}\u0026quot;) kubectl config set-cluster \u0026quot;${CLUSTER_NAME}\u0026quot; \\ --kubeconfig=\u0026quot;${KUBECFG_FILE_NAME}\u0026quot; \\ --server=\u0026quot;${ENDPOINT}\u0026quot; \\ --certificate-authority=\u0026quot;${TARGET_FOLDER}/ca.crt\u0026quot; \\ --embed-certs=true kubectl config set-credentials \\ \u0026quot;${SERVICE_ACCOUNT_NAME}-${NAMESPACE}-${CLUSTER_NAME}\u0026quot; \\ --kubeconfig=\u0026quot;${KUBECFG_FILE_NAME}\u0026quot; \\ --token=\u0026quot;${USER_TOKEN}\u0026quot; kubectl config set-context \\ \u0026quot;${SERVICE_ACCOUNT_NAME}-${NAMESPACE}-${CLUSTER_NAME}\u0026quot; \\ --kubeconfig=\u0026quot;${KUBECFG_FILE_NAME}\u0026quot; \\ --cluster=\u0026quot;${CLUSTER_NAME}\u0026quot; \\ --user=\u0026quot;${SERVICE_ACCOUNT_NAME}-${NAMESPACE}-${CLUSTER_NAME}\u0026quot; \\ --namespace=\u0026quot;${NAMESPACE}\u0026quot; kubectl config use-context \u0026quot;${SERVICE_ACCOUNT_NAME}-${NAMESPACE}-${CLUSTER_NAME}\u0026quot; \\ --kubeconfig=\u0026quot;${KUBECFG_FILE_NAME}\u0026quot;  为 cicd-user 配置权限 cat \u0026lt;\u0026lt;EOF | kubectl apply -f - kind: Role apiVersion: rbac.authorization.k8s.io/v1beta1 metadata: name: \u0026quot;${SERVICE_ACCOUNT_NAME}-role\u0026quot; namespace: \u0026quot;${NAMESPACE}\u0026quot; rules: - apiGroups: - \u0026quot;\u0026quot; - apps - extensions resources: - '*' verbs: - '*' --- kind: RoleBinding apiVersion: rbac.authorization.k8s.io/v1beta1 metadata: name: \u0026quot;${SERVICE_ACCOUNT_NAME}-role\u0026quot; namespace: \u0026quot;${NAMESPACE}\u0026quot; subjects: - kind: ServiceAccount name: \u0026quot;${SERVICE_ACCOUNT_NAME}\u0026quot; roleRef: kind: Role name: \u0026quot;${SERVICE_ACCOUNT_NAME}-role\u0026quot; apiGroup: rbac.authorization.k8s.io EOF  其他实例使用 cicd-user  将${TARGET_FOLDER}生成的k8s-cicd-user-dev-conf文件copy至其他实例~/.kube路径下改名为config使用   注意查看k8s-cicd-user-dev-conf里cluster server地址是否合法\n遇到证书ip问题请查看kubectl get pods 证书ip问题\n    ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1606449303,"objectID":"b0767e14112e2c2836bf585d27627484","permalink":"https://w3xse7en.github.io/k8s_local/40_service_account/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/k8s_local/40_service_account/","section":"k8s_local","summary":"参考 Setting up a Kubernetes CI/CD Service Account\n   场景  权限划分，cicd限定namespace=dev使用kubectl apply -f部署服务\n 创建 namespace dev  cat \u0026lt;\u0026lt;EOF | kubectl apply -f - { \u0026quot;apiVersion\u0026quot;: \u0026quot;v1\u0026quot;, \u0026quot;kind\u0026quot;: \u0026quot;Namespace\u0026quot;, \u0026quot;metadata\u0026quot;: { \u0026quot;name\u0026quot;: \u0026quot;dev\u0026quot;, \u0026quot;labels\u0026quot;: { \u0026quot;name\u0026quot;: \u0026quot;dev\u0026quot; } } } EOF  创建 service account cicd-user # 该脚本依赖 jq 组件 yum install jq -y # [可修改] SERVICE_ACCOUNT_NAME=\u0026quot;cicd-user\u0026quot; # [可修改] NAMESPACE=\u0026quot;dev\u0026quot; # [可修改] TARGET_FOLDER=\u0026quot;/home/k8s/kube\u0026quot; kubectl create sa \u0026quot;${SERVICE_ACCOUNT_NAME}\u0026quot; --namespace \u0026quot;${NAMESPACE}\u0026quot; mkdir -p \u0026quot;${TARGET_FOLDER}\u0026quot; SECRET_NAME=$(kubectl get sa \u0026quot;${SERVICE_ACCOUNT_NAME}\u0026quot; --namespace=\u0026quot;${NAMESPACE}\u0026quot; -o json | jq -r .","tags":null,"title":"创建 service account","type":"book"},{"authors":null,"categories":null,"content":" 介绍 记录在使用k8s过程中所遇到的问题，以及解决方案\n  kubectl get nodes 证书ip问题 Unable to connect to the server: x509: certificate is valid for 10.233.0.1, 172.19.157.57, 172.19.157.57, 10.233.0.1, 127.0.0.1, 172.19.157.57, 172.19.252.199, not 47.xxx.xx.x   场景  阿里云安装，全部使用私网地址，创建service account后使用kubectl从公网访问报错\n 解决方案 supplementary_addresses_in_ssl_keys 添加公网地址  vi inventory/mycluster/group_vars/k8s-cluster/k8s-cluster.yml supplementary_addresses_in_ssl_keys: [47.xxx.xx.x] # 重新安装部署，使配置生效 ansible-playbook -i inventory/mycluster/hosts.yaml --become --become-user=root cluster.yml   参考  Invalid x509 certificate for kubernetes master\n经验证kubespray v2.14.1不需要执行rm /etc/kubernetes/pki/apiserver.*\n  system:anonymous 无法访问 k8s dashboard `services \u0026quot;https:kubernetes-dashboard:\u0026quot; is forbidden: User \u0026quot;system:anonymous\u0026quot; cannot get services/proxy in the namespace \u0026quot;kube-system\u0026quot;`   解决方案 添加system:anonymous的访问权限  cat \u0026lt;\u0026lt;EOF | kubectl apply -f - kind: ClusterRole apiVersion: rbac.authorization.k8s.io/v1 metadata: name: kubernetes-dashboard-anonymous rules: - apiGroups: [\u0026quot;\u0026quot;] resources: [\u0026quot;services/proxy\u0026quot;] resourceNames: [\u0026quot;https:kubernetes-dashboard:\u0026quot;] verbs: [\u0026quot;get\u0026quot;, \u0026quot;list\u0026quot;, \u0026quot;watch\u0026quot;, \u0026quot;create\u0026quot;, \u0026quot;update\u0026quot;, \u0026quot;patch\u0026quot;, \u0026quot;delete\u0026quot;] - nonResourceURLs: [\u0026quot;/ui\u0026quot;, \u0026quot;/ui/*\u0026quot;, \u0026quot;/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/*\u0026quot;] verbs: [\u0026quot;get\u0026quot;, \u0026quot;list\u0026quot;, \u0026quot;watch\u0026quot;, \u0026quot;create\u0026quot;, \u0026quot;update\u0026quot;, \u0026quot;patch\u0026quot;, \u0026quot;delete\u0026quot;] --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: kubernetes-dashboard-anonymous roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: kubernetes-dashboard-anonymous subjects: - kind: User name: system:anonymous EOF   参考  Enable Access for Kubernetes Dashboard via external VIP or Floating IP\n  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1606449303,"objectID":"66f84ef3686abd3f1131bc770368661c","permalink":"https://w3xse7en.github.io/k8s_local/999_qa/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/k8s_local/999_qa/","section":"k8s_local","summary":"介绍 记录在使用k8s过程中所遇到的问题，以及解决方案\n  kubectl get nodes 证书ip问题 Unable to connect to the server: x509: certificate is valid for 10.233.0.1, 172.19.157.57, 172.19.157.57, 10.233.0.1, 127.0.0.1, 172.19.157.57, 172.19.252.199, not 47.xxx.xx.x   场景  阿里云安装，全部使用私网地址，创建service account后使用kubectl从公网访问报错","tags":null,"title":"solve k8s problem","type":"book"}]